\subsection{Why do the heterogeneous prediction adaptation layers work? }
Firstly, we explore the reason why the heterogeneous prediction adaptation layers work in the TRANP-CNN model. The key part of TRANP-CNN is the heterogeneous prediction adaptation layers, and in this section, we discuss why the proposed heterogeneous prediction adaptation layers work. 

The only differences between NP-CNN and TRANP-CNN is that the TRANP-CNN applies heterogeneous prediction adaptation layers, which is particularly designed for cross-project bug localization performance. This is because the distribution of data from source project and target project may be different, leading to a bias results if the prediction structure is the same. The TRANP-CNN model employs two fully-connected network for prediction, one is for source project and the other one is for target project. During training process, the source project data are trained using the feature extraction part CNN and fully-connected network $fc_s$, and the target project data are trained using the same CNN and fully-connected network $fc_t$. This process helps improve the bug localization performance from target project by enjoying the advantage in sharing the same network extracting high-level semantic features from source project, and meanwhile adapting prediction network using training data from target project. 

From the experiments results, we still find that SimpleTrans outperforms NP-CNN in terms of most evaluation metrics. SimpleTrans has the same structure with NP-CNN, but fine tune the parameters of fully-connected network using target project data, which suggests that using target project to train the fully-connected network for prediction is effective for bug localization. TRANP-CNN uses two fully-connected networks for source project and target project that further improves the bug localization performance. 

\subsection{Why does TRANP-CNN improve the bug localization performance?}

\subsection{Threats to Validity}

\dl{Ferdian, please help to fill in the blanks.}

There are three kinds of threat that may impact the validity of this study: threats to internal validity, threats to external validity, and threats to construct validity. We acknowledge these threats below.

Threats to internal validity relate to author bias and errors in our code and experiments. We have checked our code for bugs and fixed any that we can identify. There may still be errors that we do not notice though. The dataset that we obtain are taken from prior papers~\cite{zhou2012should,KochharTL14} and have been used to evaluate other bug localization techniques, e.g.,~\cite{zhou2012should,SahaLKP14,huo2016learning}. The data are bug reports taken from bug tracking systems from real projects (i.e., ....) and thus are realistic. Thus, we believe there are limited threats to the internal validity of the study. 

Threats to external validity relate to the generalizability of the study. We have analyzed data that includes ... bug reports taken from ... projects. Admittedly, the projects that we analyze may not represent all the projects out there. Still, our threats to external validity are less than existing bug localization work since the amount of data that we investigate is larger than prior work. For example, Zhou et al. only use ... bug reports from ... projects~\cite{zhou2012should}, Saha et al. only use ... bug reports from ... reports~\cite{SahaLKP14}, and Huo et al. only use ... bug reports from ... projects~\cite{huo2016learning}. In a future work, we plan to reduce the threats to external validity further by investigating more bug reports from additional projects.

Threats to construct validity relate to the suitability of our evaluation metrics. We have used ... as evaluation metrics. These metrics were also used by prior bug localization studies, e.g.,  ~\cite{zhou2012should,SahaLKP14,huo2016learning}. Thus, we believe there are limited threats to construct validity. 