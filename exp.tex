To evaluate the effectiveness of \TRANPCNN, we conduct experiments on open source software projects and compare it with several state-of-the-art bug localization methods.

\subsection{Research Questions}
\input{rq}

\subsection{Datasets}
\input{dataset}

\subsection{Evaluation Metrics}
\input{metrics}

\subsection{Baselines}

We compare our proposed model \TRANPCNN with the following baseline methods:
\begin{itemize}
  \item VSM (Vector Space Model)~\cite{rao2011retrieval}: a baseline method that first uses a Vector Space Model to represent textual contents of bug reports and source code, and then employs Logistic Regression to predict buggy source code when given a new bug report.
  \item Burak (Burak Filter)~\cite{peters2013better}: a state-of-the-art method for cross-project and cross-company defect prediction problem. It filters training sets using Burak filter by employing $k$-nearest neighbour algorithm to select instances in the source project that are most similar to instances in the test project.
  \item TCA+ (Transfer Component Analysis)~\cite{NamPK13}: a state-of-the-art transfer learning method in software engineering, which first normalizes the training sets and employs TCA to map source and target project into a single feature space and then applies Logistic Regression for bug localization (same settings suggested in their paper). 
  \item TCA+$^P$ (Transfer Component Analysis with Multi-Layer Perceptron (MLP)): a state-of-the-art transfer learning method in software engineering, which first normalizes training sets and employs TCA to map source and target project into a single feature space and then applies MLPs for bug localization~(same settings with fully-connected layers in \TRANPCNN).
   \item TCA+$^D$ (Transfer Component Analysis with Deep features): a state-of-the-art transfer learning method in software engineering, which first normalizes training sets and employs TCA to map source and target project into a single feature space and then applies Logistic Regression for bug localization (using deep features extracted from CNN instead of VSM features).
  %\item NP-CNN (Natural and Programming language Convolutional Neural Network)~\cite{huo2016learning}: a state-of-the-art deep model for bug localization, which uses a source project for training a deep CNN to localize buggy source code in the target project.
\end{itemize}
%\ft{Settings would probably better be grouped in experimental settings section. There is no citation for TCA. }

\subsection{Experimental Settings}
For the parameters of baseline methods (VSM, Burak, TCA+, TCA+$^{(P)}$, TCA+$^{(D)}$), we use the same parameter settings suggested in their work~\cite{rao2011retrieval,NamPK13}. For NP-CNN, we also use the parameter settings suggested in its paper~\cite{huo2016learning}.

For the \TRANPCNN model, we employ the most commonly used ReLU $\sigma(x)=\max(0,x)$ as the activation function and the filter windows size $d$ is set to 3, 4, 5, with 100 feature maps each in within-project feature extraction layers. The number of neurons in fully-connected network is set the same as the number of neurons in CNN. In addition, a drop-out method is also applied to prevent co-adaption of hidden units by randomly dropping out values in fully-connected layers. The drop-out probability $p$ is set to 0.25.

For data partition, we use all data from a source project and 20\% data from a target project as training sets, and locate buggy codes in 80\% remaining data from the target project. This process is repeated five times to reduce the effect of randomness. We then report the average results for comparison. 

\section{Experimental Results}

\subsection{Experimental Results for Research Questions}

\begin{table}[htbp]
  \centering
  \caption{Performance Comparisons between within-project and cross-project bug localization.}
  \resizebox{!}{0.5\columnwidth}{
    \begin{tabular}{c|l|c|c|c|c|c}
    \toprule
    Tasks & \textit{Methods} & \multicolumn{1}{l}{\textit{Top 1}} & \multicolumn{1}{l}{\textit{Top 5}} & \multicolumn{1}{l}{\textit{Top 10}} & \multicolumn{1}{l}{\textit{MAP}} & \multicolumn{1}{l}{\textit{MRR}} \\
    \midrule
    \multirow{3}[0]{*}{\textbf{J}$\rightarrow$\textbf{H}} & NP-CNN & 0.317  & 0.362  & 0.508  & 0.276  & 0.352  \\
          & NP-CNN$^{partial}$ & 0.204  & 0.258  & 0.313  & 0.202  & 0.292  \\
          & NP-CNN$^{full}$ & \textbf{0.533}  & \textbf{0.617}  & \textbf{0.650}  & \textbf{0.472}  & \textbf{0.580}  \\
          \midrule
    \multirow{3}[0]{*}{\textbf{L}$\rightarrow$\textbf{H}} & NP-CNN & 0.142  & 0.192  & 0.345  & 0.161  & 0.218  \\
          & NP-CNN$^{partial}$ & 0.204  & 0.258  & 0.313  & 0.202  & 0.292  \\
          & NP-CNN$^{full}$ & \textbf{0.533}  & \textbf{0.617}  & \textbf{0.650}  & \textbf{0.472}  & \textbf{0.580}  \\
          \midrule
    \multirow{3}[0]{*}{\textbf{H}$\rightarrow$\textbf{J}} & NP-CNN & 0.167  & 0.287  & 0.349  & 0.247  & 0.277  \\
          & NP-CNN$^{partial}$ & 0.035  & 0.211  & 0.302  & 0.155  & 0.189  \\
          & NP-CNN$^{full}$ & \textbf{0.508}  & \textbf{0.587}  & \textbf{0.679}  & \textbf{0.462}  & \textbf{0.557}  \\
          \midrule
    \multirow{3}[0]{*}{\textbf{L}$\rightarrow$\textbf{J}} & NP-CNN & 0.152  & 0.182  & 0.318  & 0.176  & 0.221  \\
          & NP-CNN$^{partial}$ & 0.035  & 0.211  & 0.302  & 0.155  & 0.189  \\
          & NP-CNN$^{full}$ & \textbf{0.508}  & \textbf{0.587}  & \textbf{0.679}  & \textbf{0.462}  & \textbf{0.557}  \\
          \midrule
    \multirow{3}[0]{*}{\textbf{H}$\rightarrow$\textbf{L}} & NP-CNN & 0.173  & 0.246  & 0.390  & 0.196  & 0.329  \\
          & NP-CNN$^{partial}$ & 0.097  & 0.219  & 0.335  & 0.095  & 0.109  \\
          & NP-CNN$^{full}$ & \textbf{0.289}  & \textbf{0.484}  & 0.611  & \textbf{0.287}  & \textbf{0.387}  \\
          \midrule
    \multirow{3}[0]{*}{\textbf{J}$\rightarrow$\textbf{L}} & NP-CNN & 0.110  & 0.255  & 0.323  & 0.141  & 0.176  \\
          & NP-CNN$^{partial}$ & 0.097  & 0.219  & 0.335  & 0.095  & 0.109  \\
          & NP-CNN$^{full}$ & \textbf{0.289}  & \textbf{0.484}  & \textbf{0.611}  & \textbf{0.287}  & \textbf{0.387}  \\
          \bottomrule
    \end{tabular}%
    }

  \label{tab:results1}%
\end{table}%


\begin{figure}[hbt]
\centering
\includegraphics[width = 0.9\columnwidth]{pic/results1_avg.pdf}
\caption{Performance comparisons between within-project and cross-project bug localization.}
\label{fig:results1}
\end{figure}


\textbf{RQ1}: \textit{Is there a need for cross-project bug localization?}

To answer this research question, we compare the results of using NP-CNN for bug localization in different settings.

\begin{itemize}
  \item NP-CNN: Directly employs NP-CNN for cross-project bug localization, which means directly training the model on the data from a source project and locating the bugs in a target project.
  \item NP-CNN$^{partial}$: Employs NP-CNN using partial data of a target project, which means training based on a partial data (20\%) from the target project, and localizing buggy files without using data from a source project.
  \item NP-CNN$^{full}$: Employs NP-CNN using full data of a target project. In this setting, we conduct a 5-fold cross-validation for comparison.
\end{itemize}

The results are detailed in Table~\ref{tab:results1} and Figure~\ref{fig:results1}. There are six tasks in the table.%, in which $\textbf{H}$ represents project \textit{HTTPClient}, $\textbf{J}$ represents project \textit{Jackrabbit} and $\textbf{L}$ represents \textit{Lucene-Java}. 
The task $\textbf{H} \rightarrow \textbf{J}$ represents using \textit{HTTPClient} as source project and predicts the location of buggy files in \textit{Jackrabbit}. The results show that the performance of bug localization using full data of the target project is the best and has a large gap against the performance of using only a partial data. For cross-project bug localization, the performance of NP-CNN that directly uses a source project is better than NP-CNN$^{partial}$, showing that cross-project data is useful to improve bug localization performance. However, directly using within-project bug localization does not work as well as NP-CNN$^{full}$. These results suggest that there is a need for cross-project bug localization, since directly using within-project bug localization method does not show a good performance.

\textbf{RQ2}: \textit{Do the project-specific prediction layers improve the bug localization performance?}

To answer this research question, we compare the results of \TRANPCNN with NP-CNN. The structural difference between \TRANPCNN and NP-CNN is on the two fully-connected networks in \TRANPCNN that combine deep features from source and target project (i.e., project-specific prediction layer), which counter the influences of cross-project data that may have different distribution and leads to a bias in performance. The results are detailed in Table~\ref{tab:results2}.

%\ft{It would be good if we can explain why such structure can counter bias. Perhaps we should explain this first in approach (theory) and then highlight it again accompanied with experimental result (empirical).}

\begin{table}[htbp]
  \centering
  \caption{Performance comparisons with previous deep models.}
  \resizebox{!}{0.35\columnwidth}{
    \begin{tabular}{c|l|c|c|c|c|c}
    \toprule
    Tasks & \textit{Methods} & \textit{Top 1} & \textit{Top 5} & \textit{Top 10} & \textit{MAP} & \textit{MRR} \\
    \midrule
    \multirow{2}[0]{*}{\textbf{J}$\rightarrow$\textbf{H}} & NP-CNN & 0.317  & 0.362  & 0.508  & 0.276  & 0.352  \\
%          & SimpleTrans & 0.354 & 0.396 & 0.563 & 0.298 & 0.395 \\
          & \TRANPCNN & \textbf{0.500}   & \textbf{0.583} & \textbf{0.625} & \textbf{0.376} & \textbf{0.543} \\
          \midrule
    \multirow{2}[0]{*}{\textbf{L}$\rightarrow$\textbf{H}} & NP-CNN & 0.142  & 0.192  & 0.345  & 0.161  & 0.218  \\
%          & SimpleTrans & 0.163 & 0.146 & 0.354 & 0.141 & 0.246 \\
          & \TRANPCNN & \textbf{0.275} & \textbf{0.35}  & \textbf{0.488} & \textbf{0.242} & \textbf{0.332} \\
          \midrule
    \multirow{2}[0]{*}{\textbf{H}$\rightarrow$\textbf{J}} & NP-CNN & 0.167  & 0.287  & 0.349  & 0.247  & 0.277  \\
%          & SimpleTrans & 0.133 & 0.324 & 0.365 & 0.273 & 0.301 \\
          & \TRANPCNN & \textbf{0.396} & \textbf{0.443} & \textbf{0.514} & \textbf{0.371} & \textbf{0.434} \\
          \midrule
    \multirow{2}[0]{*}{\textbf{L}$\rightarrow$\textbf{J}} & NP-CNN & 0.152  & 0.182  & 0.318  & 0.176  & 0.221  \\
%          & SimpleTrans & 0.144 & 0.204 & 0.382 & 0.247 & 0.249 \\
          & \TRANPCNN & \textbf{0.460}  & \textbf{0.462} & \textbf{0.488} & \textbf{0.404} & \textbf{0.478} \\
          \midrule
    \multirow{2}[0]{*}{\textbf{H}$\rightarrow$\textbf{L}} & NP-CNN & 0.173  & 0.246  & 0.390  & 0.196  & 0.329  \\
%          & SimpleTrans & 0.197 & 0.323 & 0.426 & 0.152 & 0.313 \\
          & \TRANPCNN & \textbf{0.361} & \textbf{0.445} & \textbf{0.535} & \textbf{0.279} & \textbf{0.414} \\
          \midrule
    \multirow{2}[0]{*}{\textbf{J}$\rightarrow$\textbf{L}} & NP-CNN & 0.110  & 0.255  & 0.323  & 0.141  & 0.176  \\
%          & SimpleTrans & 0.140  & 0.282 & 0.342 & 0.163 & 0.224 \\
          & \TRANPCNN & \textbf{0.301} & \textbf{0.410}  & \textbf{0.517} & \textbf{0.247} & \textbf{0.368} \\
          \bottomrule
    \end{tabular}%
    }
  \label{tab:results2}%
\end{table}%

\begin{figure}[hbt]
\centering
\includegraphics[width = 0.9\columnwidth]{pic/results2_avg.pdf}
\caption{Performance comparisons with deep models.}
\label{fig:results2}
\end{figure}

The results show that \TRANPCNN performs better than NP-CNN, which suggest that the project-specific prediction layer can improve the performance of cross-project bug localization. This layer employs two fully-connected networks to learn a separate prediction function for source and target project. This structure helps to combat bias in data distribution, as evidenced by the higher performance of \TRANPCNN as compared to NP-CNN.  

\textbf{RQ3}: \textit{Can \TRANPCNN outperform other bug localization methods?}

To answer this research question, we compare the results of \TRANPCNN with state-of-the-art methods: VSM, Burak, TCA+, TCA+$^P$, and TCA+$^D$. %VSM is a baseline technique used in a within-project bug localization and we employ it on cross-project bug localization. Burak and TCA+ have been shown to have a good performance on cross-project and cross-company defect prediction. We adopt them for cross-project bug localization. For fair comparison with TCA+, we use same normalization strategy and classifier in their original paper (Logistic Regression) and MLP (same as \TRANPCNN). 
The results are detailed in Table~\ref{tab:results3}. 

%\ft{We should directly use abbreviations of baseline names since they have been introduced in Baselines section. Explanations about baselines are also redundant. }

According to the results, we have several findings: 1.) Burak and TCA techniques perform better than VSM, indicating that transfer learning algorithms can improve the performance of cross-project bug localization; 2.) \TRANPCNN outperforms TCA+$^P$, which shows that the high-level features extracted from CNN are more informative, providing a better representation that leads to better bug localization performance; 3.) TCA+$^D$ uses deep features extracted from CNN and the performance is not as well as \TRANPCNN, which further proves that the project-specific prediction layer improves bug localization performance; 4.) \TRANPCNN obtains the best average values in terms of all evaluation metrics. Comparing to the best baseline TCA+$^{D}$, \TRANPCNN improves the results by 24.6\%, 22.6\%, 20.9\%, 21.9\%, and 17.2\% in terms of Top-1, Top-2, Top-5, MAP, and MRR, respectively. According to Mann-Whitney U-test, we find that \TRANPCNN is significantly better in terms of all evaluation metrics. The results suggest that \TRANPCNN outperforms other traditional bug localization methods and transfer learning techniques in software engineering.

%\ft{We can highlight the amount of improvement that \TRANPCNN achieves as compared to the best baseline.}

\begin{table}[htbp]
  \centering
  \caption{Performance comparisons with traditional bug localization models.}
  \resizebox{!}{0.9\columnwidth}{
    \begin{tabular}{c|l|c|c|c|c|c}
    \toprule
    Tasks & \textit{Methods} & \multicolumn{1}{c|}{\textit{Top 1}} & \multicolumn{1}{c|}{\textit{Top 5}} & \multicolumn{1}{c|}{\textit{Top 10}} & \multicolumn{1}{c|}{\textit{MAP}} & \multicolumn{1}{c}{\textit{MRR}} \\
    \midrule
    \multirow{6}[0]{*}{\textbf{J}$\rightarrow$\textbf{H}} & VSM   & 0.098  & 0.157  & 0.177  & 0.087  & 0.143  \\
          & Burak & 0.110  & 0.126  & 0.138  & 0.116  & 0.121  \\
          & TCA+ & 0.120  & 0.212  & 0.144  & 0.157  & 0.162  \\
          & TCA+$^P$ & 0.114  & 0.133  & 0.154  & 0.123  & 0.176  \\
          & TCA+$^D$ & 0.122  & 0.225  & 0.271  & 0.168  & 0.248  \\
          & \TRANPCNN & \textbf{0.500}  & \textbf{0.583}  & \textbf{0.625}  & \textbf{0.376}  & \textbf{0.543}  \\
          \midrule
    \multirow{6}[0]{*}{\textbf{L}$\rightarrow$\textbf{H}} & VSM   & 0.059  & 0.098  & 0.237  & 0.099  & 0.112  \\
          & Burak & 0.113  & 0.203  & 0.242  & 0.143  & 0.143  \\
          & TCA+ & 0.120  & 0.188  & 0.244  & 0.151  & 0.158  \\
          & TCA+$^P$ & 0.128  & 0.200  & 0.252  & 0.161  & 0.167  \\
          & TCA+$^D$ & 0.102  & 0.237  & 0.367  & 0.161  & 0.202  \\
          & \TRANPCNN & \textbf{0.275}  & \textbf{0.350}  & \textbf{0.488}  & \textbf{0.242}  & \textbf{ 0.332}  \\
          \midrule
    \multirow{6}[0]{*}{\textbf{H}$\rightarrow$\textbf{J}} & VSM   & 0.035  & 0.211  & 0.232  & 0.165  & 0.129  \\
          & Burak & 0.130  & 0.150  & 0.206  & 0.225  & 0.195  \\
          & TCA+ & 0.115  & 0.162  & 0.209  & 0.239  & 0.244  \\
          & TCA+$^P$ & 0.114  & 0.154  & 0.203  & 0.237  & 0.241  \\
          & TCA+$^D$ & 0.111  & 0.135  & 0.157  & 0.168  & 0.185  \\
          & \TRANPCNN & \textbf{0.396}  & \textbf{0.443}  & \textbf{0.514}  & \textbf{0.371}  & \textbf{0.434}  \\
          \midrule
    \multirow{6}[0]{*}{\textbf{L}$\rightarrow$\textbf{J}} & VSM   & 0.197  & 0.212  & 0.293  & 0.167  & 0.216  \\
          & Burak & 0.161  & 0.132  & 0.368  & 0.170  & 0.187  \\
          & TCA+ & 0.136  & 0.183  & 0.370  & 0.170  & 0.179  \\
          & TCA+$^P$ & 0.114  & 0.116  & 0.397  & 0.138  & 0.191  \\
          & TCA+$^D$ & 0.178  & 0.236  & 0.469  & 0.227  & 0.256  \\
          & \TRANPCNN & \textbf{0.460}  & \textbf{0.462}  & \textbf{0.488}  & \textbf{0.404}  & \textbf{0.478}  \\
          \midrule
    \multirow{6}[0]{*}{\textbf{H}$\rightarrow$\textbf{L}} & VSM   & 0.083  & 0.278  & 0.393  & 0.154  & 0.136  \\
          & Burak & 0.105  & 0.226  & 0.272  & 0.123  & 0.222  \\
          & TCA+ & 0.136  & 0.208  & 0.383  & 0.170  & 0.279  \\
          & TCA+$^P$ & 0.143  & 0.226  & 0.394  & 0.171  & 0.288  \\
          & TCA+$^D$ & 0.162  & 0.207  & 0.345  & 0.229  & 0.292  \\
          & \TRANPCNN & \textbf{0.361}  & \textbf{0.445}  & \textbf{0.535}  & \textbf{0.279}  & \textbf{0.414}  \\
          \midrule
    \multirow{6}[0]{*}{\textbf{J}$\rightarrow$\textbf{L}} & VSM   & 0.038  & 0.077  & 0.154  & 0.124  & 0.204  \\
          & Burak & 0.138  & 0.161  & 0.176  & 0.168  & 0.226  \\
          & TCA+ & 0.135  & 0.111  & 0.172  & 0.169  & 0.222  \\
          & TCA+$^P$ & 0.136  & 0.132  & 0.192  & 0.173  & 0.237  \\
          & TCA+$^D$ & 0.142  & 0.297  & 0.308  & 0.238  & 0.293  \\
          & \TRANPCNN & \textbf{0.301}  & \textbf{0.410}  & \textbf{0.517}  & \textbf{0.247}  & \textbf{0.368}  \\

          \bottomrule
    \end{tabular}%
    }
  \label{tab:results3}%
\end{table}%

\begin{figure}[hbt]
\centering
\includegraphics[width = 0.9\columnwidth]{pic/results3_avg.pdf}
\caption{Performance comparisons with traditional bug localization models.}
\label{fig:results3}
\end{figure}

